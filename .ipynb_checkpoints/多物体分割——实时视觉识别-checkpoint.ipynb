{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "# 导入必要的软件包\n",
    "import datetime\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (28, 28, 1)\n",
    "num_classes = 10\n",
    "# 模型创建模型\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#恢复模型\n",
    "model = create_model()\n",
    "model.load_weights('mnist.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image):\n",
    "    result = model.predict(a)\n",
    "    result = np.argmax(result[0])\n",
    "    return result\n",
    "\n",
    "def image_dealwith(img):\n",
    "    #图像灰度处理\n",
    "    img = cv2.imread(imgfile)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "\n",
    "    gradX = cv2.Sobel(gray, ddepth=cv2.CV_32F, dx=1, dy=0, ksize=-1)\n",
    "    gradY = cv2.Sobel(gray, ddepth=cv2.CV_32F, dx=0, dy=1, ksize=-1)\n",
    "    # subtract the y-gradient from the x-gradient\n",
    "    gradient = cv2.subtract(gradX, gradY)\n",
    "    gradient = cv2.convertScaleAbs(gradient)\n",
    "\n",
    "    # blur and threshold the image\n",
    "    blurred = cv2.blur(gradient, (9, 9))\n",
    "    (_, thresh) = cv2.threshold(blurred, 45, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 25))\n",
    "    closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # perform a series of erosions and dilations\n",
    "    closed = cv2.erode(closed, None, iterations=4)\n",
    "    closed = cv2.dilate(closed, None, iterations=4)\n",
    "    return closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# camera = cv2.VideoCapture(0)\n",
    "camera = cv2.VideoCapture(\"VideoTest1.avi\")\n",
    "time.sleep(0.25)\n",
    "\n",
    "firstFrame = None\n",
    "\n",
    "\n",
    "# 遍历视频的每一帧\n",
    "while True:\n",
    "    # 获取当前帧并初始化occupied/unoccupied文本\n",
    "    (grabbed, frame) = camera.read()\n",
    "    text = \"Unoccupied\"\n",
    " \n",
    "    # 如果不能抓取到一帧，说明我们到了视频的结尾\n",
    "    if not grabbed:\n",
    "        break\n",
    " \n",
    "    # 调整该帧的大小，转换为灰阶图像并且对其进行高斯模\n",
    "    closed = image_dealwith(frame)\n",
    "    (_,cnts, _) = cv2.findContours(closed.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for c in cnts:\n",
    "        rect = cv2.contourArea(c)\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        crop_imgae = frame[y:y+h,x:x+w]#分割图像进行识别\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        Grayimg = cv2.cvtColor(crop_imgae, cv2.COLOR_BGR2GRAY)\n",
    "        image = cv2.resize(Grayimg, (28, 28))\n",
    "        image = image.astype(\"float\") / 255.0\n",
    "        image = img_to_array(image)\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "\n",
    "        result = model.predict(image)\n",
    "        result = np.argmax(result[0])\n",
    "\n",
    "\n",
    "    # draw the text and timestamp on the frame\n",
    "        # 在当前帧上写文字以及时间戳\n",
    "        cv2.putText(fff, \"Room Status: {}\".format(result), (x, y),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "    #     cv2.putText(frame, \"Room Status: {}\".format(result), (10, 20),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "        #显示当前帧并记录用户是否按下按键\n",
    "        cv2.imshow(\"Security Feed\", frame)\n",
    "        key = cv2.waitKey(1)\n",
    "\n",
    "        # 如果q键被按下，跳出循环\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "        \n",
    " # 清理摄像机资源并关闭打开的窗口\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
